{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN-LSTM混合模型\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_channels=1, input_seq_length=10, input_features=3, \n",
    "                 conv_channels=32, lstm_hidden_size=58, num_lstm_layers=2, dropout=0.2):\n",
    "        \"\"\"\n",
    "        CNN-LSTM混合模型，先用CNN提取特征，再用LSTM处理时序关系\n",
    "        \n",
    "        参数:\n",
    "        input_channels: 输入的通道数\n",
    "        input_seq_length: 输入序列长度，这里是时间步数量\n",
    "        input_features: 每个时间步的特征数，这里是3个主成分\n",
    "        conv_channels: CNN卷积层输出的通道数\n",
    "        lstm_hidden_size: LSTM隐藏层的大小\n",
    "        num_lstm_layers: LSTM层的数量\n",
    "        dropout: Dropout比率，用于防止过拟合\n",
    "        \"\"\"\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.input_seq_length = input_seq_length\n",
    "        self.input_features = input_features\n",
    "        self.conv_channels = conv_channels\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        \n",
    "        # CNN部分 - 提取局部模式特征\n",
    "        self.conv1 = nn.Conv2d(input_channels, conv_channels, kernel_size=(2, 2), padding=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 1))  # 在时间维度上降采样，保持特征维度\n",
    "        \n",
    "        # 计算CNN输出后的时间步长度\n",
    "        self.cnn_output_seq_length = input_seq_length // 2  # 经过池化层，时间维度减半\n",
    "        \n",
    "        # 计算CNN输出后的特征维度\n",
    "        self.cnn_output_features = conv_channels * input_features\n",
    "        \n",
    "        # LSTM部分 - 处理时序依赖关系\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.cnn_output_features,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # 全连接层 - 映射到输出\n",
    "        self.fc = nn.Linear(lstm_hidden_size, 1)\n",
    "        \n",
    "        # Dropout层\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 添加通道维度 (batch_size, seq_len, features) -> (batch_size, channels, seq_len, features)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # CNN前向传播\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # 重塑张量，准备输入LSTM\n",
    "        # (batch_size, channels, cnn_output_seq_length, features) -> \n",
    "        # (batch_size, cnn_output_seq_length, channels*features)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape(batch_size, self.cnn_output_seq_length, self.cnn_output_features)\n",
    "        \n",
    "        # LSTM前向传播\n",
    "        h0 = torch.zeros(self.num_lstm_layers, batch_size, self.lstm_hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_lstm_layers, batch_size, self.lstm_hidden_size).to(x.device)\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # 只取最后一个时间步的输出\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # 应用dropout\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # 全连接层映射到输出\n",
    "        output = self.fc(lstm_out)\n",
    "        \n",
    "        return output.squeeze()  # 输出形状为(batch_size,)\n",
    "model = CNNLSTMModel(\n",
    "    input_channels=1,\n",
    "    input_seq_length=10,  # 序列长度\n",
    "    input_features=3,     # 3个主成分\n",
    "    conv_channels=32,     # CNN卷积层通道数\n",
    "    lstm_hidden_size=64,  # LSTM隐藏层大小\n",
    "    num_lstm_layers=2,    # LSTM层数\n",
    "    dropout=0.2           # Dropout比率\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # 添加L2正则化\n",
    "\n",
    "# 添加学习率调度器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 200  # 增加epoch数量以获得更好的性能\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 25  # 提前停止的轮数\n",
    "patience_counter = 0\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "print(f\"模型总参数数量: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪，防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 计算每个epoch的平均训练损失\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_test_tensor)\n",
    "        val_loss = criterion(val_outputs, y_test_tensor).item()\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 更新学习率调度器\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 提前停止\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # 保存最佳模型\n",
    "            torch.save(model.state_dict(), 'best_cnn_lstm_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'提前停止训练！Epoch {epoch+1}')\n",
    "                break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('best_cnn_lstm_model.pth'))\n",
    "\n",
    "# 评估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 对训练集进行预测\n",
    "    train_predictions = model(X_train_tensor).numpy()\n",
    "    \n",
    "    # 对测试集进行预测\n",
    "    test_predictions_cnnlstm = model(X_test_tensor).numpy()\n",
    "\n",
    "# 反归一化处理\n",
    "# y_train = scaler_y.inverse_transform(y_train.reshape(-1,1))\n",
    "train_predictions = scaler_y.inverse_transform(train_predictions.reshape(-1,1))\n",
    "# y_test = scaler_y.inverse_transform(y_test.reshape(-1,1))\n",
    "test_predictions_cnnlstm = scaler_y.inverse_transform(test_predictions_cnnlstm.reshape(-1,1))\n",
    "\n",
    "\n",
    "# 计算评估指标\n",
    "train_rmse_cnnlstm = math.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "train_mae_cnnlstm = mean_absolute_error(y_train, train_predictions)\n",
    "train_r2_cnnlstm = r2_score(y_train, train_predictions)\n",
    "\n",
    "test_rmse_cnnlstm = math.sqrt(mean_squared_error(y_test, test_predictions_cnnlstm))\n",
    "test_mae_cnnlstm = mean_absolute_error(y_test, test_predictions_cnnlstm)\n",
    "test_r2_cnnlstm = r2_score(y_test, test_predictions_cnnlstm)\n",
    "\n",
    "print(\"\\n评估指标:\")\n",
    "print(f\"训练集 - RMSE: {train_rmse_cnnlstm:.3f}, MAE: {train_mae_cnnlstm:.3f}, R²: {train_r2_cnnlstm:.4f}\")\n",
    "print(f\"测试集 - RMSE: {test_rmse_cnnlstm:.3f}, MAE: {test_mae_cnnlstm:.3f}, R²: {test_r2_cnnlstm:.4f}\")\n",
    "\n",
    "# 可视化预测结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, label='Real', color='blue')\n",
    "plt.plot(test_predictions_cnnlstm, label='Predict', color='orange')\n",
    "plt.legend()\n",
    "plt.title('CNN-LSTM Model Prediction Results')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.grid(True)\n",
    "plt.savefig('cnn_lstm_prediction.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 可视化训练和验证损失曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('cnn_lstm_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
